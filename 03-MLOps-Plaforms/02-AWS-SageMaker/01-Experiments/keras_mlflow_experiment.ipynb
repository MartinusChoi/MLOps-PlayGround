{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8438de-898a-4f48-a519-f69658372396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:46:36.026540Z",
     "iopub.status.busy": "2025-08-21T05:46:36.021660Z",
     "iopub.status.idle": "2025-08-21T05:46:43.315877Z",
     "shell.execute_reply": "2025-08-21T05:46:43.314692Z",
     "shell.execute_reply.started": "2025-08-21T05:46:36.026311Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q mlflow\n",
    "!pip install --upgrade -q boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3efba897-c68a-4ac1-9a0f-ff96e3aa67f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:46:43.320619Z",
     "iopub.status.busy": "2025-08-21T05:46:43.317330Z",
     "iopub.status.idle": "2025-08-21T05:47:02.786825Z",
     "shell.execute_reply": "2025-08-21T05:47:02.785829Z",
     "shell.execute_reply.started": "2025-08-21T05:46:43.320579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 05:46:50.523470: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-21 05:46:52.441549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-21 05:46:57.785347: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccef4e0f-135a-4d2c-b7e7-37a6d48f71b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:02.789440Z",
     "iopub.status.busy": "2025-08-21T05:47:02.788413Z",
     "iopub.status.idle": "2025-08-21T05:47:02.794130Z",
     "shell.execute_reply": "2025-08-21T05:47:02.792982Z",
     "shell.execute_reply.started": "2025-08-21T05:47:02.789397Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('arn:aws:sagemaker:ap-southeast-2:954690186719:mlflow-tracking-server/SageMaker-Experiment-Lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096338d6-75fe-449c-86b2-f354d9f0e28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:02.796424Z",
     "iopub.status.busy": "2025-08-21T05:47:02.795781Z",
     "iopub.status.idle": "2025-08-21T05:47:02.820752Z",
     "shell.execute_reply": "2025-08-21T05:47:02.818222Z",
     "shell.execute_reply.started": "2025-08-21T05:47:02.796399Z"
    }
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e28d79d-50e4-4c2b-ae8f-4a193fd65df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:02.825183Z",
     "iopub.status.busy": "2025-08-21T05:47:02.824630Z",
     "iopub.status.idle": "2025-08-21T05:47:04.980938Z",
     "shell.execute_reply": "2025-08-21T05:47:04.980021Z",
     "shell.execute_reply.started": "2025-08-21T05:47:02.825155Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "train_input_path = os.path.join('datasets', 'train_input.npy')\n",
    "test_input_path = os.path.join('datasets', 'test_input.npy')\n",
    "train_target_path = os.path.join('datasets', 'train_target.npy')\n",
    "test_target_path = os.path.join('datasets', 'test_target.npy')\n",
    "\n",
    "s3_client.download_file(\n",
    "    f'sagemaker-example-files-prod-{region}',\n",
    "    os.path.join('datasets', 'image', 'MNIST', 'numpy', 'input_train.npy'),\n",
    "    train_input_path\n",
    ")\n",
    "\n",
    "s3_client.download_file(\n",
    "    f'sagemaker-example-files-prod-{region}',\n",
    "    os.path.join('datasets', 'image', 'MNIST', 'numpy', 'input_test.npy'),\n",
    "    test_input_path\n",
    ")\n",
    "\n",
    "s3_client.download_file(\n",
    "    f'sagemaker-example-files-prod-{region}',\n",
    "    os.path.join('datasets', 'image', 'MNIST', 'numpy', 'input_train_labels.npy'),\n",
    "    train_target_path\n",
    ")\n",
    "\n",
    "s3_client.download_file(\n",
    "    f'sagemaker-example-files-prod-{region}',\n",
    "    os.path.join('datasets', 'image', 'MNIST', 'numpy', 'input_test_labels.npy'),\n",
    "    test_target_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4fa94b-0958-46f7-9e67-7b6382f11d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:04.983247Z",
     "iopub.status.busy": "2025-08-21T05:47:04.981825Z",
     "iopub.status.idle": "2025-08-21T05:47:04.996804Z",
     "shell.execute_reply": "2025-08-21T05:47:04.995327Z",
     "shell.execute_reply.started": "2025-08-21T05:47:04.983211Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(train_input_path, test_input_path, train_target_path, test_target_path, num_classes=10):\n",
    "    train_input = np.load(train_input_path)\n",
    "    test_input = np.load(test_input_path)\n",
    "    train_target = np.load(train_target_path)\n",
    "    test_target = np.load(test_target_path)\n",
    "\n",
    "    train_input = np.reshape(train_input, (60000, 28, 28))\n",
    "    test_input = np.reshape(test_input, (10000, 28, 28))\n",
    "    train_target = np.reshape(train_target, (60000,))\n",
    "    test_target = np.reshape(test_target, (10000,))\n",
    "\n",
    "    train_input = train_input.astype(\"float32\") / 255\n",
    "    test_input = test_input.astype(\"float32\") / 255\n",
    "\n",
    "    train_input = np.expand_dims(train_input, -1)\n",
    "    test_input = np.expand_dims(test_input, -1)\n",
    "\n",
    "    train_target = keras.utils.to_categorical(train_target, num_classes)\n",
    "    test_target = keras.utils.to_categorical(test_target, num_classes)\n",
    "\n",
    "    print(\n",
    "        f\"Train Inpu Shape : {train_input.shape}\",\n",
    "        f\"\\n{train_input.shape[0]} train samples\",\n",
    "        f\"\\n{test_input.shape[0]} test samples\"\n",
    "    )\n",
    "\n",
    "    return train_input, test_input, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb26409-5df3-4263-88ae-c4de7275884e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:04.998702Z",
     "iopub.status.busy": "2025-08-21T05:47:04.998116Z",
     "iopub.status.idle": "2025-08-21T05:47:05.980725Z",
     "shell.execute_reply": "2025-08-21T05:47:05.979683Z",
     "shell.execute_reply.started": "2025-08-21T05:47:04.998670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Inpu Shape : (60000, 28, 28, 1) \n",
      "60000 train samples \n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, test_input, train_target, test_target = load_datasets(\n",
    "    train_input_path = train_input_path,\n",
    "    test_input_path = test_input_path,\n",
    "    train_target_path = train_target_path,\n",
    "    test_target_path = test_target_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82fa5c65-f023-4241-8630-a632e58883f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:58:48.084892Z",
     "iopub.status.busy": "2025-08-21T05:58:48.084399Z",
     "iopub.status.idle": "2025-08-21T05:58:48.090056Z",
     "shell.execute_reply": "2025-08-21T05:58:48.089181Z",
     "shell.execute_reply.started": "2025-08-21T05:58:48.084868Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'input_shape' : (28,28,1),\n",
    "    'num_classes' : 10\n",
    "}\n",
    "\n",
    "PARAM = {\n",
    "    'batch_size' : 256,\n",
    "    'epochs' : 8,\n",
    "    'dropout' : 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5344a31d-8f76-4b64-927a-d2bfe74e943e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:47:05.989201Z",
     "iopub.status.busy": "2025-08-21T05:47:05.988322Z",
     "iopub.status.idle": "2025-08-21T05:47:05.996870Z",
     "shell.execute_reply": "2025-08-21T05:47:05.995123Z",
     "shell.execute_reply.started": "2025-08-21T05:47:05.989135Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape, num_classes, dropout=0.5):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "            layers.MaxPool2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "            layers.MaxPool2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1d3181-908e-4c60-a7bf-2a94fa5a3ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:58:58.133259Z",
     "iopub.status.busy": "2025-08-21T05:58:58.132616Z",
     "iopub.status.idle": "2025-08-21T05:58:58.182253Z",
     "shell.execute_reply": "2025-08-21T05:58:58.180822Z",
     "shell.execute_reply.started": "2025-08-21T05:58:58.133232Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    input_shape=CFG['input_shape'],\n",
    "    num_classes=CFG['num_classes'],\n",
    "    dropout=PARAM['dropout']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f45912-3645-474f-83d4-e74551fa4c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:59:02.724909Z",
     "iopub.status.busy": "2025-08-21T05:59:02.716845Z",
     "iopub.status.idle": "2025-08-21T05:59:02.768505Z",
     "shell.execute_reply": "2025-08-21T05:59:02.767658Z",
     "shell.execute_reply.started": "2025-08-21T05:59:02.722410Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, run=None):\n",
    "        super().__init__()\n",
    "        self.run = run  # mlflow의 run context (선택)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # logs 딕셔너리의 모든 키(metric) 기록\n",
    "        if logs is not None:\n",
    "            for key, value in logs.items():\n",
    "                mlflow.log_metric(key, value, step=epoch)\n",
    "                print(f\"\\n{key} -> {logs[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f7281f-7bde-4fce-b3dc-c65b86b98056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T05:59:09.843613Z",
     "iopub.status.busy": "2025-08-21T05:59:09.843204Z",
     "iopub.status.idle": "2025-08-21T06:05:32.320751Z",
     "shell.execute_reply": "2025-08-21T06:05:32.319976Z",
     "shell.execute_reply.started": "2025-08-21T05:59:09.843588Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 05:59:11.640065: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 169344000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7058 - loss: 0.9696\n",
      "accuracy -> 0.856925904750824\n",
      "\n",
      "loss -> 0.48390501737594604\n",
      "\n",
      "val_accuracy -> 0.9731666445732117\n",
      "\n",
      "val_loss -> 0.10326249897480011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 149ms/step - accuracy: 0.7065 - loss: 0.9674 - val_accuracy: 0.9732 - val_loss: 0.1033\n",
      "Epoch 2/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9610 - loss: 0.1314\n",
      "accuracy -> 0.9643333554267883\n",
      "\n",
      "loss -> 0.1195259690284729\n",
      "\n",
      "val_accuracy -> 0.9815000295639038\n",
      "\n",
      "val_loss -> 0.06386993080377579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 190ms/step - accuracy: 0.9610 - loss: 0.1313 - val_accuracy: 0.9815 - val_loss: 0.0639\n",
      "Epoch 3/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9732 - loss: 0.0889\n",
      "accuracy -> 0.9734259247779846\n",
      "\n",
      "loss -> 0.08618266135454178\n",
      "\n",
      "val_accuracy -> 0.984333336353302\n",
      "\n",
      "val_loss -> 0.05696840584278107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 163ms/step - accuracy: 0.9732 - loss: 0.0889 - val_accuracy: 0.9843 - val_loss: 0.0570\n",
      "Epoch 4/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.9768 - loss: 0.0755\n",
      "accuracy -> 0.9780370593070984\n",
      "\n",
      "loss -> 0.07107127457857132\n",
      "\n",
      "val_accuracy -> 0.9865000247955322\n",
      "\n",
      "val_loss -> 0.04748576506972313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 150ms/step - accuracy: 0.9768 - loss: 0.0755 - val_accuracy: 0.9865 - val_loss: 0.0475\n",
      "Epoch 5/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9799 - loss: 0.0649\n",
      "accuracy -> 0.9809259176254272\n",
      "\n",
      "loss -> 0.06232111155986786\n",
      "\n",
      "val_accuracy -> 0.987333357334137\n",
      "\n",
      "val_loss -> 0.04161537066102028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 166ms/step - accuracy: 0.9799 - loss: 0.0649 - val_accuracy: 0.9873 - val_loss: 0.0416\n",
      "Epoch 6/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9841 - loss: 0.0521\n",
      "accuracy -> 0.9833518266677856\n",
      "\n",
      "loss -> 0.05359245091676712\n",
      "\n",
      "val_accuracy -> 0.9879999756813049\n",
      "\n",
      "val_loss -> 0.04158106446266174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 214ms/step - accuracy: 0.9841 - loss: 0.0521 - val_accuracy: 0.9880 - val_loss: 0.0416\n",
      "Epoch 7/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9853 - loss: 0.0486\n",
      "accuracy -> 0.9850925803184509\n",
      "\n",
      "loss -> 0.04786858335137367\n",
      "\n",
      "val_accuracy -> 0.9878333210945129\n",
      "\n",
      "val_loss -> 0.04144691303372383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 164ms/step - accuracy: 0.9853 - loss: 0.0486 - val_accuracy: 0.9878 - val_loss: 0.0414\n",
      "Epoch 8/8\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9859 - loss: 0.0444\n",
      "accuracy -> 0.9862037301063538\n",
      "\n",
      "loss -> 0.044576164335012436\n",
      "\n",
      "val_accuracy -> 0.9901666641235352\n",
      "\n",
      "val_loss -> 0.03727125748991966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 158ms/step - accuracy: 0.9859 - loss: 0.0444 - val_accuracy: 0.9902 - val_loss: 0.0373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/21 06:05:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0397\n",
      "Test Loss : 0.03252928704023361\n",
      "Test Accuracy : 0.989300012588501\n",
      "🏃 View run keras-exp-2 at: https://ap-southeast-2.experiments.sagemaker.aws/#/experiments/2/runs/a48cffce7a1e4f04ab16c26f3b0987ad\n",
      "🧪 View experiment at: https://ap-southeast-2.experiments.sagemaker.aws/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"keras-mlflow-experiment-lab\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"keras-exp-2\") as run:\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    mlflow.log_param('BatchSize', PARAM['batch_size'])\n",
    "    mlflow.log_param('Epochs', PARAM['epochs'])\n",
    "    mlflow.log_param('Dropout', PARAM['dropout'])\n",
    "\n",
    "    mlflow.log_artifact(train_input_path)\n",
    "    mlflow.log_artifact(train_target_path)\n",
    "    mlflow.log_artifact(test_input_path)\n",
    "    mlflow.log_artifact(test_target_path)\n",
    "\n",
    "    model.fit(\n",
    "        train_input,\n",
    "        train_target,\n",
    "        batch_size=PARAM['batch_size'],\n",
    "        epochs=PARAM['epochs'],\n",
    "        validation_split=0.1,\n",
    "        callbacks=[ExperimentCallback(run=run)]\n",
    "    )\n",
    "\n",
    "    score = model.evaluate(test_input, test_target)\n",
    "    print(f\"Test Loss : {score[0]}\\nTest Accuracy : {score[1]}\")\n",
    "\n",
    "    mlflow.log_metric(\"TestLoss_CrossEntropy\", score[0])\n",
    "    mlflow.log_metric(\"TestAccuracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56c50e-eee0-48eb-8691-27830a0f5341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
